{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Group 11\n",
    "\n",
    "Members:  Alessandro Casati (6544649),  Bas van den Muijsenberg (5797578) , Hylke Bleeker (5589355), Jan-Pieter Vermeer (6340261),  Mike Geerts (6276210)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Objective\n",
    "\n",
    "## Analysis and delay prediction of flights across top 20 airports in Europe in 2023-24\n",
    "\n",
    "**Research Question**  \n",
    "What factors drive airport delays across the top 10 European airports in 2023-24, and can we build predictive models to identify possible delays for a flight using the information available?\n",
    "\n",
    "**Sub Questions**\n",
    "- What type of delays are occurring most at the airports?\n",
    "- Which airports experience the highest, the lowest delay, and most consistent delay rates?\n",
    "- How do delays relate to traffic volume and efficiency?\n",
    "- How do delays distribute geographically across Europe, and which airports stand out as persistent “delay hotspots”?\n",
    "- Which features (traffic levels, weekday/weekend, month, etc.) are the strongest predictors of high-delay days?\n",
    "- What model can predict the chance of delay and the amount delay for a flight?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contribution Statement\n",
    "\n",
    "*Be specific. Some of the tasks can be coding (expect everyone to do this), background research, conceptualisation, visualisation, data analysis, data modelling*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author 1**:\n",
    "\n",
    "**Author 2**:\n",
    "\n",
    "**Author 3**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Used\n",
    "\n",
    "## Datasets\n",
    "| Dataset | Dataset description (function) | Columns needed |\n",
    "|---|---|---|\n",
    "| Airport Traffic | Airport capacity of inbound and outbound flights for network manager and airport operator | All |\n",
    "| Airport ATFM_Delay | The Airport Arrival ATFM Delay provides an indication of ATFM delays on the ground due to constraints at airports | FLT_DATE, APT_ICAO (to merge DB) + all the remaining types of delays |\n",
    "| Airport Punctuality | Daily performance tracker of airport punctuality, delays, and operational efficiency | All + add APT_ICAO for merging |\n",
    "| All_Pre_Departure_Delays | Daily overview of total pre-departure delay in minutes per airport that includes all delay causes | All |\n",
    "| ATC_Pre_Departure_Delay | Proxy for ATC induced delays at the departure stand (IATA delay code 89) | Pending (depends on data analysis findings) |\n",
    "| Additional taxi-out time | Taxi time from gate to runway and associated delay | All |\n",
    "| Additional taxi-in time | Taxi time from runway to gate and associated delay | All |\n",
    "\n",
    "## Information extracted from datasets\n",
    "| Dataset | Key Information |\n",
    "|---|---|\n",
    "| Airport Traffic | IFR arrivals, departures for Airport Operator and Network Manager |\n",
    "| Airport ATFM_Delay | Disruption type and count, number of delayed arrival flights |\n",
    "| Airport Punctuality | Arrival & departure punctuality %, avg delay (dep & arr), operated schedules % |\n",
    "| Pre_Departure_Delay | AO departures, AO pre-departure delay (minutes) |\n",
    "| Additional taxi-out time | Number of flights with available data + total taxi in time |\n",
    "| Additional taxi-in time | Number of flights with available data + total taxi out time |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline\n",
    "\n",
    "## Data Exploration & Cleaning\n",
    "- Import & clean the datasets: remove missing/invalid values, select only useful columns and merge.\n",
    "- Create basic delay metrics:\n",
    "  - Delay categories (On time, Delayed, Delayed15)\n",
    "  - Day category (Weekend, Weekdays)\n",
    "\n",
    "## Descriptive Data Analysis\n",
    "- Time patterns: heatmaps/line charts/stacked charts (delays by day, month, cause).\n",
    "- Geospatial view: interactive maps color-coded by average airport delay.\n",
    "- Efficiency scatterplots: traffic volume vs. % delay\n",
    "\n",
    "## Predictive Modeling\n",
    "- Predict delay occurrence for a flight using departure airport and its performances, average airport delay, weekday/weekend & month.\n",
    "- Models: Logistic Regression and/or Random Forest.\n",
    "- Testing with 2025 data (unseen during training).\n",
    "\n",
    "## Clustering & Patterns\n",
    "- Cluster airports by daily delay patterns (e.g., “always congested,” “seasonal peaks,” “mostly smooth”)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO-DO list, by Wed 8/10\n",
    "| Dataset | Key Information | Assigned to |\n",
    "|---|---|---|\n",
    "| Airport Traffic | Imported + top20 defined: missing total number of departures and arrivals | Ale |\n",
    "| Airport ATFM_Delay | Extract top20 aiports by comparing it with df_top10 and overall and sum for all the 2 years | Bas |\n",
    "| Airport Punctuality | Filter for 23-24, find top 20, compare with df_top20 (some airports might be missing), get all the columns | Mike |\n",
    "| Pre_Departure_Delay | TBD. is the data actually useful for our RQ, if yes extract top20 + last 5 columns | JP |\n",
    "| Additional taxi-out time | Extract top20 airports + TF, TOT_REF_NB_FL, TOT_REF&ADD_TIME_MIN, PIVOT_LABEL | Hylke |\n",
    "| Additional taxi-in time | Extract top20 airports + TF, TOT_REF_NB_FL, TOT_REF&ADD_TIME_MIN, PIVOT_LABEL | Hylke |\n",
    "\n",
    "Some comments: for now we focus on the totals for 2023-24 (combined). Watch out that some datasets don't have matching columns and you can't merge them together, you might need to compare them manually or use other references (especially for Punctuality dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airport Traffic\n",
    "Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AT = pd.read_excel(\"datasets/AirportTraffic.xlsx\")\n",
    "df_TIn = pd.read_excel(\"datasets/Taxi-In_Additional_Time.xlsx\")\n",
    "df_TOut = pd.read_excel(\"datasets/Taxi-Out_Additional_Time.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find top 20 airports by total flights and create a new dataframe with key data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top20 = (\n",
    "    df_AT.groupby(\"APT_ICAO\")[[\"FLT_TOT_1\", \"FLT_DEP_1\", \"FLT_ARR_1\"]] #Group by airport code\n",
    "    .sum().sort_values(by=\"FLT_TOT_1\",ascending=False) #Sum the values for each code of the 3 columns indicated\n",
    "    .head(20).reset_index()) #Change \"20\" to change the number of airports analysed\n",
    "# Adding airport's city name and state from original dataset\n",
    "df_top20 = (df_top20.merge(df_AT[[\"APT_ICAO\", \"APT_NAME\", \"STATE_NAME\"]]\n",
    "                           .drop_duplicates(), on=\"APT_ICAO\", how=\"left\"))\n",
    "df_top20.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airport ATFM_Delay\n",
    "Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AAD = pd.read_excel(\"datasets/AA_ATFM_Delay.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delay for every day and all top 20 airports.\n",
    "Removing Na, and only top 20 airports, sorted by airport traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AAD = df_AAD.dropna()\n",
    "df_AAD_top20 = df_AAD[df_AAD[\"APT_ICAO\"].isin(df_top20[\"APT_ICAO\"])]\n",
    "\n",
    "#Lists of code and names of top20 airports\n",
    "airports_name_list = df_top20[\"APT_NAME\"].tolist()\n",
    "airports_code_list = df_top20[\"APT_ICAO\"].tolist()\n",
    "\n",
    "#Dataframe of codes, useful for merging \n",
    "df_airport_codes = pd.DataFrame({'APT_ICAO': airports_code_list})\n",
    "\n",
    "df_AAD_top20 = df_AAD_top20.set_index(\"APT_ICAO\").loc[airports_code_list].reset_index()\n",
    "\n",
    "#df_AAD_top20.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total delay for every airport "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATFM_cols = df_AAD.columns[7:27].tolist() #Columns neded\n",
    "\n",
    "df_AAD_total_delays_per_airport = (\n",
    "    df_AAD_top20[df_AAD_top20[\"APT_ICAO\"].isin(airports_code_list)].groupby([\"APT_ICAO\", \"APT_NAME\", \"STATE_NAME\"])[ATFM_cols]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "order = df_top20[\"APT_ICAO\"].tolist()\n",
    "df_AAD_total_delays_per_airport = df_AAD_total_delays_per_airport.set_index(\"APT_ICAO\").loc[order].reset_index() #Do we care for the order?\n",
    "\n",
    "df_AAD_total_delays_per_airport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airport Punctionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.gitkeep', 'AA_ATFM_Delay.xlsx', 'Airports_Punctuality.xlsx', 'AirportTraffic.xlsx', 'ATC_Pre_Departure_Delay.xlsx', 'Taxi-In_Additional_Time.xlsx', 'Taxi-Out_Additional_Time.xlsx']\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/AirportPunctuality.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m----> 6\u001b[0m df_AP \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/AirportPunctuality.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m df_AT \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/AirportTraffic.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m#We normalise the columns here:\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mmjhg\\.jupyter\\lab\\Anaconda\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m ExcelFile(\n\u001b[0;32m    496\u001b[0m         io,\n\u001b[0;32m    497\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    498\u001b[0m         engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[0;32m    499\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\mmjhg\\.jupyter\\lab\\Anaconda\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1550\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1548\u001b[0m     ext \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxls\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1549\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1550\u001b[0m     ext \u001b[38;5;241m=\u001b[39m inspect_excel_format(\n\u001b[0;32m   1551\u001b[0m         content_or_path\u001b[38;5;241m=\u001b[39mpath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options\n\u001b[0;32m   1552\u001b[0m     )\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ext \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1554\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1555\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExcel file format cannot be determined, you must specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1556\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man engine manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1557\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\mmjhg\\.jupyter\\lab\\Anaconda\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1402\u001b[0m, in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(content_or_path, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[0;32m   1400\u001b[0m     content_or_path \u001b[38;5;241m=\u001b[39m BytesIO(content_or_path)\n\u001b[1;32m-> 1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m   1403\u001b[0m     content_or_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m, storage_options\u001b[38;5;241m=\u001b[39mstorage_options, is_text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1404\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m   1405\u001b[0m     stream \u001b[38;5;241m=\u001b[39m handle\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   1406\u001b[0m     stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mmjhg\\.jupyter\\lab\\Anaconda\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'datasets/AirportPunctuality.xlsx'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"datasets\"))\n",
    "\n",
    "df_AP = pd.read_excel(\"datasets/AirportPunctuality.xlsx\")\n",
    "df_AT = pd.read_excel(\"datasets/AirportTraffic.xlsx\")\n",
    "\n",
    "#We normalise the columns here:\n",
    "df_AP.columns = df_AP.columns.str.strip().str.upper()\n",
    "df_AT.columns = df_AT.columns.str.strip().str.upper()\n",
    "\n",
    "#Here we filter on the years 2023 and 2024:\n",
    "if 'YEAR' in df_AP.columns:\n",
    "    df_AP = df_AP[(df_AP['YEAR'] == 2023) | (df_AP['YEAR'] == 2024)]\n",
    "elif 'FLT_DATE' in df_AP.columns:\n",
    "    df_AP['FLT_DATE'] = pd.to_datetime(df_AP['FLT_DATE'], errors='coerce')\n",
    "    df_AP = df_AP[df_AP['FLT_DATE'].dt.year.isin([2023, 2024])]\n",
    "\n",
    "#Below we find the top 20 airports based on the number of flights\n",
    "flight_col_candidates = [c for c in df_AP.columns if 'FLT' in c and 'TOT' in c]\n",
    "if flight_col_candidates:\n",
    "    main_flight_col = flight_col_candidates[0]  \n",
    "else:\n",
    "    main_flight_col = None\n",
    "\n",
    "if main_flight_col:\n",
    "    df_AP_top20 = (\n",
    "        df_AP.groupby(\"APT_ICAO\")[main_flight_col]\n",
    "        .sum()\n",
    "        .sort_values(ascending=False)\n",
    "        .head(20)\n",
    "        .reset_index()\n",
    "    )\n",
    "else:\n",
    "    df_AP_top20 = (\n",
    "        df_AP.groupby(\"APT_ICAO\")\n",
    "        .size()\n",
    "        .sort_values(ascending=False)\n",
    "        .head(20)\n",
    "        .reset_index(name='ENTRY_COUNT')\n",
    "    )\n",
    "\n",
    "#We try to add names of airports and countries\n",
    "extra_cols = [col for col in ['APT_NAME', 'STATE_NAME'] if col in df_AP.columns]\n",
    "if extra_cols:\n",
    "    df_AP_top20 = df_AP_top20.merge(\n",
    "        df_AP[['APT_ICAO'] + extra_cols].drop_duplicates(),\n",
    "        on='APT_ICAO',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "#We compare with the df_top20 from AirportTraffic since some airports might be missing\n",
    "df_top20_AT = (\n",
    "    df_AT.groupby(\"APT_ICAO\")[[\"FLT_TOT_1\"]]\n",
    "    .sum()\n",
    "    .sort_values(by=\"FLT_TOT_1\", ascending=False)\n",
    "    .head(20)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "#Lists of ICAO-codes\n",
    "codes_punctuality = set(df_AP_top20[\"APT_ICAO\"].tolist())\n",
    "codes_traffic = set(df_top20_AT[\"APT_ICAO\"].tolist())\n",
    "\n",
    "missing_in_punctuality = codes_traffic - codes_punctuality\n",
    "missing_in_traffic = codes_punctuality - codes_traffic\n",
    "\n",
    "print(\"Airports in Traffic top20 but missing in Punctuality data:\")\n",
    "print(missing_in_punctuality)\n",
    "print(\"\\nAirports in Punctuality top20 but not in Traffic top20:\")\n",
    "print(missing_in_traffic)\n",
    "\n",
    "#Finally, we find all colums\n",
    "common_codes = list(codes_punctuality & codes_traffic)\n",
    "df_AP_top20_final = df_AP[df_AP[\"APT_ICAO\"].isin(common_codes)].copy()\n",
    "\n",
    "print(\"\\n✅ Airport Punctuality top20 dataset (2023–24) klaar:\")\n",
    "print(df_AP_top20_final.head())\n",
    "\n",
    "# Optioneel: opslaan\n",
    "df_AP_top20_final.to_csv(\"data/processed/AirportPunctuality_Top20_2023_2024.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taxi In & Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi_time_in = (\n",
    "    df_TIn[(df_TIn[\"APT_ICAO\"].isin(airports_code_list)) & \n",
    "           ((df_TIn[\"YEAR\"] == 2023) | (df_TIn[\"YEAR\"] == 2024))]\n",
    "    .groupby(\"APT_ICAO\")[[\"VALID_FL\", \"TOTAL_REF_NB_FL\", \"TOTAL_REF_TIME_MIN\", \"TOTAL_ADD_TIME_MIN\"]]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "#In order: filter only airports in top 20, filter only values from 2023-24, group by code and sum the values in the \n",
    "#listed columns, reset the index to have the codes as a column itselft (useful for merging)\n",
    "\n",
    "# Rename the columns to for in values\n",
    "in_cols_to_rename = {\n",
    "    \"VALID_FL\": \"VALID_FL_IN\",\n",
    "    \"TOTAL_REF_NB_FL\": \"TOTAL_REF_NB_FL_IN\",\n",
    "    \"TOTAL_REF_TIME_MIN\": \"TOT_REF_TIME_MIN_IN\",\n",
    "    \"TOTAL_ADD_TIME_MIN\": \"TOT_ADD_TIME_MIN_IN\"\n",
    "}\n",
    "df_taxi_time_in = df_taxi_time_in.rename(columns=in_cols_to_rename)\n",
    "\n",
    "# Merging taxi with airport codes\n",
    "df_taxi_time_final = pd.merge(df_airport_codes, df_taxi_time_in, on='APT_ICAO', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi_time_out = (\n",
    "    df_TOut[(df_TOut[\"APT_ICAO\"].isin(airports_code_list)) & \n",
    "           ((df_TOut[\"YEAR\"] == 2023) | (df_TOut[\"YEAR\"] == 2024))]\n",
    "    .groupby(\"APT_ICAO\")[[\"VALID_FL\", \"TOTAL_REF_NB_FL\", \"TOTAL_REF_TIME_MIN\", \"TOTAL_ADD_TIME_MIN\"]]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "#Same operations as df_taxi_time_in\n",
    "\n",
    "# Rename the columns to for out values\n",
    "out_cols_to_rename = {\n",
    "    \"VALID_FL\": \"VALID_FL_OUT\",\n",
    "    \"TOTAL_REF_NB_FL\": \"TOTAL_REF_NB_FL_OUT\",\n",
    "    \"TOTAL_REF_TIME_MIN\": \"TOT_REF_TIME_MIN_OUT\",\n",
    "    \"TOTAL_ADD_TIME_MIN\": \"TOT_ADD_TIME_MIN_OUT\"\n",
    "}\n",
    "df_taxi_time_out = df_taxi_time_out.rename(columns=out_cols_to_rename)\n",
    "\n",
    "# Merging taxi in with taxi out\n",
    "df_taxi_time = pd.merge(df_taxi_time_final, df_taxi_time_out, on='APT_ICAO', how='left')\n",
    "\n",
    "print(df_taxi_time.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
