{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5718296",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "For predicting the delay of a flight we need: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4a9d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fc4cc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AT = pd.read_excel(\"datasets/AirportTraffic.xlsx\")\n",
    "df_TIn = pd.read_excel(\"datasets/Taxi-In_Additional_Time.xlsx\")\n",
    "df_TOut = pd.read_excel(\"datasets/Taxi-Out_Additional_Time.xlsx\")\n",
    "df_AAD = pd.read_excel(\"datasets/AA_ATFM_Delay.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "377b393e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AAD[\"FLT_DATE\"] = df_AT[\"FLT_DATE\"].dt.strftime(\"%-d-%b-%Y\")\n",
    "df_AAD[\"Is_Weekend\"] = df_AT[\"FLT_DATE\"].dt.dayofweek.isin([5, 6]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fccfead",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AT['FLT_DATE'] = pd.to_datetime(df_AT['FLT_DATE'])\n",
    "day_of_week = df_AT['FLT_DATE'].dt.dayofweek\n",
    "\n",
    "# Create the new column ('Is_Weekend'): 1 yes, 0 no\n",
    "df_AT['Is_Weekend'] = np.where(day_of_week >= 5, 1, 0)\n",
    "df_AT[\"Is_Weekend\"] = df_AT[\"Is_Weekend\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22768e3",
   "metadata": {},
   "source": [
    "Prepare AT dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e6a9362",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top20 = (\n",
    "    df_AT.groupby([\"APT_ICAO\"])[[\"FLT_TOT_1\", \"FLT_DEP_1\", \"FLT_ARR_1\"]] #Group by airport code\n",
    "    .sum().sort_values(by=\"FLT_TOT_1\",ascending=False) #Sum the values for each code of the 3 columns indicated\n",
    "    .head(20).reset_index()) #Change \"20\" to change the number of airports analysed\n",
    "# Adding airport's city name and state from original dataset\n",
    "df_top20 = (df_top20.merge(df_AT[[\"APT_ICAO\", \"APT_NAME\", \"STATE_NAME\"]]\n",
    "                           .drop_duplicates(), on=\"APT_ICAO\", how=\"left\"))\n",
    "\n",
    "airports_code_list = df_top20[\"APT_ICAO\"].tolist()\n",
    "df_airport_codes = pd.DataFrame({'APT_ICAO': airports_code_list})\n",
    "#print(df_top20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee1a8028",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AT_top20_pred = df_AT[df_AT[\"APT_ICAO\"].isin(airports_code_list)]\n",
    "\n",
    "df_AT_top20_pred = (\n",
    "    df_AT_top20_pred.groupby([\"APT_ICAO\", \"MONTH_NUM\", \"Is_Weekend\"])[[\"FLT_TOT_1\", \"FLT_DEP_1\", \"FLT_ARR_1\"]] #Group by airport code\n",
    "    .sum().sort_values(by=\"FLT_TOT_1\",ascending=False) #Sum the values for each code of the 3 columns indicated\n",
    "    .reset_index())\n",
    "#print(df_AT_top20_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b831acb",
   "metadata": {},
   "source": [
    "Prepare Taxis time dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "181aec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taxi_time_in = (\n",
    "    df_TIn[(df_TIn[\"APT_ICAO\"].isin(airports_code_list)) & \n",
    "           ((df_TIn[\"YEAR\"] == 2023) | (df_TIn[\"YEAR\"] == 2024))]\n",
    "    .groupby([\"APT_ICAO\", \"MONTH_NUM\"])[[\"VALID_FL\", \"TOTAL_REF_NB_FL\", \"TOTAL_REF_TIME_MIN\", \"TOTAL_ADD_TIME_MIN\"]]\n",
    "    .sum().drop_duplicates()\n",
    "    .reset_index()\n",
    ")\n",
    "#In order: filter only airports in top 20, filter only values from 2023-24, group by code and sum the values in the \n",
    "#listed columns, reset the index to have the codes as a column itselft (useful for merging)\n",
    "\n",
    "# Rename the columns to for in values\n",
    "in_cols_to_rename = {\n",
    "    \"VALID_FL\": \"VALID_FL_IN\",\n",
    "    \"TOTAL_REF_NB_FL\": \"TOTAL_REF_NB_FL_IN\",\n",
    "    \"TOTAL_REF_TIME_MIN\": \"TOT_REF_TIME_MIN_IN\",\n",
    "    \"TOTAL_ADD_TIME_MIN\": \"TOT_ADD_TIME_MIN_IN\"\n",
    "}\n",
    "df_taxi_time_in = df_taxi_time_in.rename(columns=in_cols_to_rename)\n",
    "# Merging taxi with airport codes\n",
    "df_taxi_time_final = pd.merge(df_airport_codes, df_taxi_time_in, on='APT_ICAO', how='left')\n",
    "\n",
    "df_taxi_time_out = (\n",
    "    df_TOut[(df_TOut[\"APT_ICAO\"].isin(airports_code_list)) & \n",
    "           ((df_TOut[\"YEAR\"] == 2023) | (df_TOut[\"YEAR\"] == 2024))]\n",
    "    .groupby([\"APT_ICAO\", \"MONTH_NUM\"])[[\"VALID_FL\", \"TOTAL_REF_NB_FL\", \"TOTAL_REF_TIME_MIN\", \"TOTAL_ADD_TIME_MIN\"]]\n",
    "    .sum()\n",
    "    .drop_duplicates()\n",
    "    .reset_index()\n",
    ")\n",
    "#Same operations as df_taxi_time_in\n",
    "\n",
    "# Rename the columns to for out values\n",
    "out_cols_to_rename = {\n",
    "    \"VALID_FL\": \"VALID_FL_OUT\",\n",
    "    \"TOTAL_REF_NB_FL\": \"TOTAL_REF_NB_FL_OUT\",\n",
    "    \"TOTAL_REF_TIME_MIN\": \"TOT_REF_TIME_MIN_OUT\",\n",
    "    \"TOTAL_ADD_TIME_MIN\": \"TOT_ADD_TIME_MIN_OUT\"\n",
    "}\n",
    "df_taxi_time_out = df_taxi_time_out.rename(columns=out_cols_to_rename)\n",
    "# Merging taxi in with taxi out\n",
    "df_taxi_time = pd.merge(df_taxi_time_final, df_taxi_time_out, on=[\"APT_ICAO\", \"MONTH_NUM\"], how='left')\n",
    "\n",
    "#print(df_taxi_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a19a74",
   "metadata": {},
   "source": [
    "Prepare ATFM Dataset, both with average and total causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e166a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_AAD = df_AAD.dropna()\n",
    "df_AAD_top20 = df_AAD[df_AAD[\"APT_ICAO\"].isin(airports_code_list)]\n",
    "ATFM_cols = df_AAD.columns[7:27].tolist() #Columns neded\n",
    "\n",
    "df_AAD_tot_delays_per_airport = (\n",
    "    df_AAD_top20.groupby([\"APT_ICAO\", \"MONTH_NUM\", \"Is_Weekend\"])[ATFM_cols]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "df_AAD_avg_delays_per_airport = (\n",
    "    df_AAD_top20.groupby([\"APT_ICAO\", \"MONTH_NUM\", \"Is_Weekend\"])[ATFM_cols]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    ")\n",
    "#df_AAD_avg_delays_per_airport.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53b63cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_complete = pd.merge(df_AT_top20_pred, df_AAD_tot_delays_per_airport, on=[\"APT_ICAO\", \"MONTH_NUM\", \"Is_Weekend\"], how=\"left\")\n",
    "df_complete = pd.merge(df_complete, df_taxi_time, on=[\"APT_ICAO\", \"MONTH_NUM\"], how=\"left\")\n",
    "df_complete.sort_values(by=[\"APT_ICAO\", \"MONTH_NUM\"])\n",
    "\n",
    "df_complete[\"Delay_Rate\"] = df_complete.FLT_ARR_1_DLY_15/df_complete.FLT_TOT_1\n",
    "df_complete[\"Delay_Prone\"] = (df_complete.Delay_Rate > 0.005).astype(int) #0.005 is an example, we need to find it within first 3 questions\n",
    "\n",
    "df_complete.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca9382c",
   "metadata": {},
   "source": [
    "Creating training dataset (2023-2024): we will predict binary variable \"Delay_Prone\" using all the other variables in a logistic regression.\n",
    "\n",
    "HP: we assume that 2023-24-25 are years with similar characteristics (previous ones were influenced by covid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29502985",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_complete[[\"APT_ICAO\", \"MONTH_NUM\", \"Is_Weekend\", \"FLT_TOT_1\", \"FLT_DEP_1\", \"FLT_ARR_1_x\", \"Delay_Rate\", \"Delay_Prone\"]].dropna()\n",
    "airport_mean_delay = df.groupby(\"APT_ICAO\")[\"Delay_Rate\"].mean()\n",
    "df[\"ICAO_AVG_DELAY_RATE\"] = df[\"APT_ICAO\"].map(airport_mean_delay)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6713591e",
   "metadata": {},
   "source": [
    "## Data normalization and usability\n",
    "\n",
    "Logistic regression is sensitive to feature scales: large numeric ranges can dominate smaller ones, therefore we need to normalize some of the numerical variables. Moreover we need to check the count of delayed airports to determine whether we have enough data for each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "88bef69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ba3335",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"MONTH_NUM\", \"Is_Weekend\", \"FLT_TOT_1\", \"FLT_DEP_1\", \"FLT_ARR_1_x\", \"ICAO_AVG_DELAY_RATE\"] # Model features\n",
    "X = df[features] # predictors\n",
    "y = df[\"Delay_Prone\"] # predicted variable\n",
    "\n",
    "numeric_features = [\"MONTH_NUM\", \"FLT_TOT_1\", \"FLT_DEP_1\", \"FLT_ARR_1_x\", \"ICAO_AVG_DELAY_RATE\"] # to be scaled\n",
    "categorical_features = [\"Is_Weekend\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features), # features to be scaled\n",
    "        (\"cat\", \"passthrough\", categorical_features) # features that don't need transformations\n",
    "    ]\n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor), # Actual scaling\n",
    "    (\"classifier\", LogisticRegression(class_weight=\"balanced\")) # Model used, we use balanced weight to moderate class split \n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=55) # Dataset split\n",
    "\n",
    "model.fit(X_train, y_train)# Model training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9b1abf",
   "metadata": {},
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f22cc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88d81fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred)) # (TP + TN)/(FP + FN)\n",
    "print(confusion_matrix(y_test, y_pred)) # [TP, FP], [FN, TN]\n",
    "print(classification_report(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475bf069",
   "metadata": {},
   "source": [
    "False Negatives are very high -> The model predicted as not delayed many airports that are actually delayed, while its very good the other way around\n",
    "\n",
    "Let's add more variables to the model and see if the accuracy increases, without overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a133fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(by=[\"APT_ICAO\", \"MONTH_NUM\"])\n",
    "\n",
    "df[\"PM_DelayRate\"] = df.groupby(\"APT_ICAO\")[\"ICAO_AVG_DELAY_RATE\"].shift(1)\n",
    "df[\"PM_FLT_TOT_1\"] = df.groupby(\"APT_ICAO\")[\"FLT_TOT_1\"].shift(1)\n",
    "df[\"PM_DepRatio\"] = df.groupby(\"APT_ICAO\")[\"FLT_DEP_1\"].shift(1) / df.groupby(\"APT_ICAO\")[\"FLT_TOT_1\"].shift(1)\n",
    "df[\"PM_ArrRatio\"] = df.groupby(\"APT_ICAO\")[\"FLT_ARR_1_x\"].shift(1) / df.groupby(\"APT_ICAO\")[\"FLT_TOT_1\"].shift(1)\n",
    "\n",
    "df.fillna(0, inplace=True) # Fill NaN for first month of each airport (Jan 2023)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3c47ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"MONTH_NUM\", \"Is_Weekend\", \"FLT_TOT_1\", \"ICAO_AVG_DELAY_RATE\", \n",
    "            \"PM_DelayRate\", \"PM_FLT_TOT_1\", \"PM_DepRatio\", \"PM_ArrRatio\"]\n",
    "X = df[features]\n",
    "y = df[\"Delay_Prone\"]\n",
    "\n",
    "numeric_features = [\"MONTH_NUM\", \"FLT_TOT_1\", \"ICAO_AVG_DELAY_RATE\", \n",
    "                    \"PM_DelayRate\", \"PM_FLT_TOT_1\", \"PM_DepRatio\", \"PM_ArrRatio\"]\n",
    "categorical_features = [\"Is_Weekend\"]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numeric_features),\n",
    "        (\"cat\", \"passthrough\", categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_2 = Pipeline(steps=[\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=55)\n",
    "\n",
    "model_2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a13cc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_2.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238d89a3",
   "metadata": {},
   "source": [
    "Accuracy didn't increase, false negatives are still very high!\n",
    "\n",
    "Up next: (1) try random forest model, (2) change the variables used to predict, (3) try to cross validate results "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TIL6022-25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
